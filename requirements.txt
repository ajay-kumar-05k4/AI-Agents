# LangChain packages for AI agent functionality
langchain-ollama>=0.1.0
langchain-community>=0.0.20
langchain-core>=0.1.0

# OpenAI support (for cloud deployment)
langchain-openai>=0.0.5

# Streamlit for web UI (required for Chatbot.py)
streamlit>=1.28.0

# HTTP client (dependency of langchain-ollama)
httpx>=0.24.0

# Note: Make sure Ollama is installed and running on your system for local deployment
# Download from: https://ollama.ai/
# Pull the model: ollama pull llama3.2:1b

# DEPLOYMENT NOTES:
# 
# LOCAL DEPLOYMENT (with Ollama):
#   - Just run: streamlit run Chatbot.py
#   - Make sure Ollama is running locally
#
# CLOUD DEPLOYMENT (Streamlit Cloud, etc.):
#   Option 1 - Use OpenAI (Recommended for cloud):
#     Set environment variables in Streamlit Cloud:
#     - LLM_PROVIDER=openai
#     - OPENAI_API_KEY=your-openai-api-key
#     - OPENAI_MODEL=gpt-3.5-turbo (optional, defaults to gpt-3.5-turbo)
#
#   Option 2 - Use remote Ollama server:
#     Set environment variables:
#     - LLM_PROVIDER=ollama
#     - OLLAMA_BASE_URL=http://your-ollama-server:11434
